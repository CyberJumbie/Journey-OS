# S-F-19-2: ChatPanel Component

**Epic:** E-19 (Workbench UI)
**Feature:** F-09
**Sprint:** 7
**Lane:** faculty (P3)
**Size:** L

## User Story
As a **Faculty member**, I need a CopilotKit-powered chat panel with real-time SSE streaming display so that I can conversationally generate and refine assessment items while seeing results stream in live.

## Acceptance Criteria
- [ ] ChatPanel organism integrates CopilotKit `<CopilotChat>` component
- [ ] Messages display with role indicators (user, assistant, system)
- [ ] SSE streaming tokens render incrementally (typewriter effect) with <500ms to first token
- [ ] Pipeline progress bar: shows current node (e.g., "Generating vignette... step 3/14")
- [ ] Generated question preview card renders inline when generation completes
- [ ] Conversational refinement: user can say "make the vignette longer" and pipeline re-runs targeted node
- [ ] Message history persisted per session in Supabase `generation_sessions` table
- [ ] Input area: multiline text input with send button and `Enter` to send / `Shift+Enter` for newline
- [ ] Empty state: onboarding prompt suggestions ("Generate a cardiology question about...")
- [ ] Error display: pipeline errors shown as dismissible alert within chat
- [ ] 12-15 API tests: message rendering, streaming display, session persistence, error handling, refinement flow, CopilotKit integration
- [ ] Named exports only, TypeScript strict, design tokens only

## Implementation Layers
| Layer | Package | Files |
|-------|---------|-------|
| Types | packages/types | `src/workbench/chat.types.ts` |
| Atoms | packages/ui | `src/atoms/chat-bubble.tsx`, `src/atoms/streaming-text.tsx` |
| Molecules | packages/ui | `src/molecules/chat-input.tsx`, `src/molecules/progress-bar.tsx` |
| Organisms | apps/web | `src/components/workbench/chat-panel.tsx`, `src/components/workbench/question-preview-card.tsx` |
| Service | apps/web | `src/services/generation-stream.service.ts` |
| Hooks | apps/web | `src/hooks/use-generation-stream.ts`, `src/hooks/use-chat-session.ts` |
| Tests | apps/web | `src/tests/workbench/chat-panel.test.tsx`, `src/tests/workbench/generation-stream.test.ts` |

## Dependencies
- **Blocks:** none
- **Blocked by:** S-F-19-1 (SplitPane layout), S-F-18-4 (SSE streaming)
- **Cross-epic:** S-F-18-4 (Sprint 6 streaming)

## Notes
- CopilotKit provides `useCopilotChat` hook â€” wrap with custom `useGenerationStream` for SSE STATE_DELTA parsing
- StreamingText atom handles incremental token rendering with cursor animation
- QuestionPreviewCard renders the complete generated item in NBME-style format (vignette, stem, options A-E)
- Session persistence: create `generation_sessions` table with columns: id, user_id, course_id, messages JSONB, created_at, updated_at
- Refinement works by sending a new message that includes the previous generation context; pipeline re-enters at the relevant node
- CopilotKit runtime must be configured in apps/server with the LangGraph pipeline as a tool
