# S-F-18-4: SSE Streaming Integration

**Epic:** E-18 (LangGraph.js Generation Pipeline)
**Feature:** F-09
**Sprint:** 6
**Lane:** faculty (P3)
**Size:** M

## User Story
As a **Faculty member**, I need real-time SSE streaming of pipeline progress so that I can see each generation step as it happens and interact with the system conversationally via CopilotKit.

## Acceptance Criteria
- [ ] SSE endpoint `POST /api/generation/stream` returns `text/event-stream` response
- [ ] CopilotKit STATE_DELTA protocol implemented: events for node-enter, node-complete, token-stream, error
- [ ] Each pipeline node emits streaming tokens as they are generated (not buffered until completion)
- [ ] Progress indicators: current node name, step N/14, estimated time remaining
- [ ] Heartbeat events every 15s to prevent connection timeout
- [ ] Client reconnection support via `Last-Event-ID` header
- [ ] Graceful error streaming: pipeline errors sent as structured SSE events, not connection drops
- [ ] Generation cancellation: client sends abort, server cancels in-flight LLM calls
- [ ] <500ms to first SSE event after request
- [ ] 8-12 API tests: stream format validation, reconnection, cancellation, error events, heartbeat, auth guard
- [ ] Named exports only, TypeScript strict

## Implementation Layers
| Layer | Package | Files |
|-------|---------|-------|
| Types | packages/types | `src/generation/streaming.types.ts` |
| Controller | apps/server | `src/controllers/generation.controller.ts` |
| Service | apps/server | `src/services/generation/streaming.service.ts` |
| Middleware | apps/server | `src/middleware/sse.middleware.ts` |
| Tests | apps/server | `src/tests/generation/streaming.service.test.ts`, `src/tests/generation/generation.controller.test.ts` |

## Dependencies
- **Blocks:** S-F-19-1, S-F-19-2
- **Blocked by:** S-F-18-1 (pipeline scaffold must exist to stream from)
- **Cross-epic:** none

## Notes
- SSE, not WebSocket — per architecture rules, SSE for streaming generation events, Socket.io for presence only
- CopilotKit STATE_DELTA format: `event: state_delta\ndata: {"node":"vignette-gen","delta":{"text":"The patient..."}}\n\n`
- Use `AbortController` on the server to propagate client cancellation to LLM provider calls
- Express response: `res.setHeader('Content-Type', 'text/event-stream')`, `res.setHeader('Cache-Control', 'no-cache')`, `res.setHeader('Connection', 'keep-alive')`
- LangGraph.js `.stream()` method returns an async iterable — pipe directly to SSE response
- Auth: validate JWT before opening SSE connection, reject unauthorized with 401 (not a stream)
- Rate limiting: max 3 concurrent generation streams per user
